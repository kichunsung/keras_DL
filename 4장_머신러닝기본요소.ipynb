{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 머신러닝 네가지 분류  \n",
    "  \n",
    "### 4.1.1 지도학습  \n",
    "대부분 분류와 회귀  \n",
    "  \n",
    "### 4.1.2 비지도학습  \n",
    "데이터 노이즈 제거 또는 데이터 상관관계 이해를 위해  \n",
    "  \n",
    "### 4.1.3 자기 주도 학습  \n",
    "지도학습이지만 사람이 만든 레이블을 사용하지 않음.  \n",
    "사람이 개입하지않는 지도학습.  \n",
    "ex) 오토인코더  \n",
    "지도와 비지도 사이에서 애매하게 해석됨.  \n",
    "  \n",
    "### 4.1.4 강화학습  \n",
    "에이전트가 어떠한 환경에 놓였을 때 어떠한 행동을 한 뒤 얻는 보상을 최대화 하는 알고리즘.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류와 회귀에서 사용하는 용어  \n",
    "\n",
    "샘플 입력  \n",
    "예측 출럭  \n",
    "타깃  \n",
    "예측 오차 or 손실 값  \n",
    "클래스  \n",
    "레이블  \n",
    "참값 또는 꼬리표  \n",
    "이진분류  \n",
    "다중분류  \n",
    "다중 레이블 분류  \n",
    "스칼라 회귀  \n",
    "벡터 회귀  \n",
    "미니배치 또는 배치  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 모델평가  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 훈련 검증 테스트 세트  \n",
    "보통 8:1:1 로 나누어 사용한다.   \n",
    "데이터가 적을경우 검증 데이터는 뺀다.  \n",
    "완전히 새로운 데이터에 대한 예측\n",
    "  \n",
    "- 단순 홀드아웃 검증  \n",
    "- K-fold 교차검증  \n",
    "- 셔플링을 사용한 반복 k-fold 교차검증  \n",
    "마지막껄 캐글에서 많이사용하고있음. 정교함.비용이 많이듬.  \n",
    "  \n",
    "### 평가방식에서 유념해야할 것  \n",
    "- 대표성 있는 데이터  \n",
    "- 시간의 방향  \n",
    "- 데이터의 중복은 허용하지않는다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 데이터 전처리, 특성공학, 특성학습  \n",
    "\n",
    "### 4.3.1 데이터 전처리  \n",
    "\n",
    "#### 벡터화  \n",
    "신경망에서는 모든 입력과 타긴은 부동 소수 데이터로 이루어진 텐서여야한다!!  \n",
    "\n",
    "#### 값 정규화\n",
    "스케일 차이가 너무나면 네트워크 학습에 크리티컬하다.  \n",
    "\n",
    "#### 누락된 값 다루기\n",
    "누락된 값이 없는 데이터로 훈련하면 누락된 값을 무시하는 방법을 모른다.  \n",
    "마치 실패없는 성공이없다는것이다..  \n",
    "고의적으로 만들어야함!!\n",
    "\n",
    "### 4.3.2 특성 공학  \n",
    "학습을 편리하게! 퍼포먼스를 올리기위해! 데이터 표현방법의 차이!  \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 과대적합 과소적합  \n",
    "  \n",
    "머신러닝은 최적화와 일반화 사이의 줄다리기\n",
    "\n",
    "좋은방법은 더많은 훈련 데이터를 모으는 것 <-- 불가능하지않나...ㅠ_ㅠ\n",
    "\n",
    "과대적합을 피하는 처리과정을 규제 (regularization)이라 함.\n",
    "  \n",
    "   \n",
    "   \n",
    "### 4.4.1 네트워크 크기 축소  \n",
    "- 네트워크의 크기는 학습과정을 통해 최적의 크기를 정해야 한다.  \n",
    "\n",
    "### 4.4.2 가중치 규제 추가  \n",
    " - L1 규제 : 절댓값에 비례하는 비용 추가.\n",
    " - L2 규제 : 제곱에 비례하는 비용 추가.  \n",
    " \n",
    "### 4.4.3 드랍아웃 추가  \n",
    " 토론토 대학 제프리 힌튼과 그의 학생들.... (TMI)  \n",
    " 은행에서의 부정 방지 메커니즘에서 착안.\n",
    " \n",
    " \n",
    "###  정리 - 과대적합 방지  \n",
    "  - 훈련데이터를 모은다.  \n",
    "  - 네트워크의 용량을 감소시킨다.\n",
    "  - 가중치 규제를 추가한다.\n",
    "  - 드랍아웃을 추가한다.\n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 보편적인 머신러닝 작업 Flow  \n",
    "\n",
    "### 4.5.1 문제 정의와 데이터셋 수집  \n",
    "\n",
    "1. 문제 정의  \n",
    "무엇을 하려 하는가?  \n",
    "2. 가설 정립  \n",
    "우리는 예측가능한 충분한 훈련데이터가 있고 서로 상관이 있는 데이터라고 믿는다!.  \n",
    "\n",
    "**  머신러닝은 훈련 데이터에 있는 패턴을 기억하기위해서만 사용한다.\n",
    "\n",
    "### 4.5.2 성공 지표 선택  \n",
    "\n",
    "- 모델을 최적화할 수 있는 손실 함수를 선택하는 기준이 됨.  \n",
    "\n",
    "분류 문제에서는 정확도와 ROC AUC 가  일반적인 지표  \n",
    "불균형 클래스의 경우 정밀도와 재현율 사용.  \n",
    "랭킹문제나 다중 레이블 문제는 평균 정밀도를 사용.  \n",
    "  \n",
    "\n",
    "캐글의 데이터 과학 경연대회를 살펴 보는것을 추천.  \n",
    "\n",
    "### 4.5.3 평가 방법 선택  \n",
    "- 홀드아웃 검증 세트 분리  \n",
    "::데이터가 풍부할 때.  \n",
    "- K-fold 교차검증  \n",
    "::홀드아웃을 사용하기에 샘플의 수가 너무 적을 때.  \n",
    "- 반복 K-fold 교차 검증  \n",
    "::데이터가 적고 매우 정확한 모델 평가가 필요할 때.  \n",
    "\n",
    "대부분 첫번째로 충분함.  \n",
    "  \n",
    "### 4.5.4 데이터 준비  \n",
    "\n",
    "- 데이터는 텐서로 구성.  \n",
    "- 일반적으로 스케일 조정이 되어있음(정규화)  \n",
    "- 특성마다 범위가 다르면 정규화를 해야함.  \n",
    "- 특성공학을 수행할 수도 있음.(특히 데이터가 적을 때)  \n",
    "  \n",
    "### 4.5.5 기본보다 나은 모델 훈련  \n",
    "통계적 검정력을 달성하는 것.  \n",
    "\n",
    "가정을 잘 가정했다고 한다면 다음단계는 아래와 같음.\n",
    "\n",
    " - 마지막층 활성화 함수 선택  \n",
    " 출력에 필요한 제한을 가함.  \n",
    " - 손실 함수 선택  \n",
    " 문제의 종류에 따른 적절한 손실함수 선택.  \n",
    " - 최적화 설정  \n",
    " 옵티마이저, 학습률의 선택.  \n",
    "\n",
    "  \n",
    "  \n",
    "|        문제 유형         | 마지막층 활성화 함수 |     손실 함수      |\n",
    "| :----------------------: | :------------------: | :----------------: |\n",
    "|         이진분류         |      시그모이드      |     binary_ce      |\n",
    "|  단일 레이블 다중 분류   |      소프트맥스      |   categorical_ce   |\n",
    "|  다중 레이블 다중 분류   |      시그모이드      |     binary_ce      |\n",
    "|   임의 값에 대한 회귀    |         없음         |        mse         |\n",
    "| 0과 1사이 값에 대한 회귀 |      시그모이드      | mse 또는 binary_ce |  \n",
    "\n",
    "### 4.5.6 몸집 키우기: 과대적합 모델 구축  \n",
    "\n",
    "충분한 층과 파라미터가 있나??  \n",
    "\n",
    " - 층을 추가  \n",
    " - 층의 크기를 키움  \n",
    " - 더 많은 에포크 동안 훈련  \n",
    "\n",
    "### 4.5.7 모델 규제와 하이퍼파라미터 튜닝  \n",
    "\n",
    "반복적으로 모델을 수정하고 훈련하고 검증데이터에서 평가.  \n",
    "\n",
    "- 드랍아웃 추가  \n",
    "- 층추가 또는 제거로 구조변화 시도  \n",
    "- L1,L2 선택 혹은 모두 적용  \n",
    "- 하이퍼 파라미터 변경 시도 (유닛수, 옵티마이저, 학습률 등)  \n",
    "- 특성 공학 시도  \n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_3.5_keras",
   "language": "python",
   "name": "env_3.5_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
